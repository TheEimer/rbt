defaults:
  - cluster/local
  - search_space: dqn
  - override hydra/sweeper: HyperSMAC

hydra:
  sweeper:
    budget: 10_000_000
    budget_variable: autorl.n_total_timesteps
    search_space: ${search_space}
    sweeper_kwargs:
      optimizer_kwargs:
        smac_facade: 
          _target_: smac.facade.multi_fidelity_facade.MultiFidelityFacade
          _partial_: true
        intensifier: 
          _target_: smac.facade.multi_fidelity_facade.MultiFidelityFacade.get_intensifier
          _partial_: true
          eta: 3
        scenario:
          n_trials: 45
          seed: ${smac_seed}
          min_budget: 5
          max_budget: 50
          deterministic: false
          n_workers: 1
  run:
    dir: results/dqn_${autorl.env_name}/${autorl.seed}
  sweep:
    dir: results/dqn_${autorl.env_name}/${autorl.seed}
  job:
    chdir: true

load_checkpoint: ""
smac_seed: 0

autorl:
  seed: 42
  env_framework: "gymnax"
  env_name: "CartPole-v1"
  n_envs: 10
  algorithm: "dqn"
  cnn_policy: False
  checkpoint: []
  checkpoint_name: "default_checkpoint"
  checkpoint_dir: "/tmp"
  objectives: ["reward_mean"]
  optimize_objectives: "upper"
  state_features: ["grad_info"]
  n_steps: 10
  n_total_timesteps: 1e5
  n_eval_steps: 100
  n_eval_episodes: 10

hp_config:
  lr: 0.01
  buffer_size: 1000000
  buffer_batch_size: 64
  buffer_prio_sampling: False
  buffer_alpha: 0.9
  buffer_beta: 0.9
  buffer_epsilon: 0.00001
  gamma: 0.99
  epsilon: 0.1
  tau: 0.1
  use_target_network: True
  train_frequency: 4
  gradient_steps: 1
  target_network_update_freq: 10
  learning_starts: 1000
